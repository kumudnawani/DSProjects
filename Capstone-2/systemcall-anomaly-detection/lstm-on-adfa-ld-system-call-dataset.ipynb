{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System call Anomaly Detection- Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADFA Dataset Preprocessing:**\n",
    "\n",
    "    1. The system call language model estimates the probability distribution of the next call in a sequence given the sequence of previous calls. \n",
    "       \n",
    "    2. We assume that the host system generates a finite number of system calls. \n",
    "    \n",
    "    3. We index each system call by using an integer starting from 1 and denote the fixed set of all possible system calls in the system as S = {1, · · · , K}. Let x = x1x2 · · · xl(xi ∈ S) denote a sequence of l system calls.\n",
    "       \n",
    "**LSTM Based Model :**     \n",
    "\n",
    "    1. At the Input Layer, the call at each time step xi is fed into the model in the form of one-hot encoding,\n",
    "       in other words, a K dimensional vector with all elements zero except position xi.\n",
    "       \n",
    "    2. At the Embedding Layer*, incoming calls are embedded to continuous space by multiplying embedding matrix W,\n",
    "       which should be learned. \n",
    "       \n",
    "    3. At the Hidden Layer*, the LSTM unit has an internal state, and this state is updated recurrently at each time step.\n",
    "    \n",
    "    4. At the Output Layer, a softmax activation function is used to produce the estimation of normalized probability values of possible calls coming next in the sequence.\n",
    "    \n",
    "**References for systemcalls:**\n",
    "    1. http://osinside.net/syscall/system_call_table.htm\n",
    "    2. https://www.cs.unm.edu/~immsec/systemcalls.htm    \n",
    "    3. https://github.com/karpathy/char-rnn\n",
    "    4. https://keras.io/losses/#categorical_crossentropy\n",
    "    5. http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADFA Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug  1 13:52:35 2019\n",
    "\n",
    "@author: kuna\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "# ignore all user warnings\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "def saveintopickle(obj, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print (\"[Pickle]: save object into {}\".format(filename))\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def loadfrompickle(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "#draw the  process bar\n",
    "def drawProgressBar(percent, barLen = 20):\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    progress = \"\"\n",
    "    for i in range(barLen):\n",
    "        if i < int(barLen * percent):\n",
    "            progress += \"=\"\n",
    "        else:\n",
    "            progress += \" \"\n",
    "    sys.stdout.write(\"[ %s ] %.2f%%\" % (progress, percent * 100))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import io_helper\n",
    "\n",
    "\n",
    "random_data_dup = 10  # each sample randomly duplicated between 0 and 9 times, see dropin function\n",
    "\n",
    "\n",
    "def dropin(X, y):\n",
    "    \"\"\"\n",
    "    The name suggests the inverse of dropout, i.e. adding more samples. See Data Augmentation section at\n",
    "    http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/\n",
    "    :param X: Each row is a training sequence\n",
    "    :param y: Tne target we train and will later predict\n",
    "    :return: new augmented X, y\n",
    "    \"\"\"\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    X_hat = []\n",
    "    y_hat = []\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0, np.random.random_integers(0, random_data_dup)):\n",
    "            X_hat.append(X[i, :])\n",
    "            y_hat.append(y[i])\n",
    "    return np.asarray(X_hat), np.asarray(y_hat)\n",
    "\n",
    "\n",
    "\n",
    "def preprocess():\n",
    "\n",
    "    arrayfile = \"./array_test.pickle\"\n",
    "    array = loadfrompickle(arrayfile)\n",
    "    #print(type(array))\n",
    "    #print(array)\n",
    "    x_train = array[:,:-1]\n",
    "    y_train = array[:,-1]\n",
    "\n",
    "    print (\"The train data size is that \")\n",
    "    print (x_train.shape)\n",
    "    print (y_train.shape)\n",
    "    return (x_train,y_train)\n",
    "\n",
    "def preprocess_val():\n",
    "\n",
    "    arrayfile = \"./array_val.pickle\"\n",
    "    array = loadfrompickle(arrayfile)\n",
    "    #print(type(array))\n",
    "    #print(array)\n",
    "    x_test = array[:,:-1]\n",
    "    y_test = array[:,-1]\n",
    "\n",
    "    print (\"The train data size is that \")\n",
    "    print (x_test.shape)\n",
    "    print (y_test.shape)\n",
    "    return (x_test,y_test)\n",
    "\n",
    "#if __name__ ==\"__main__\":\n",
    "#   preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834\n",
      "Skip the file ADFA-LD/Training_Data_Master/.DS_Store\n",
      "The total unique elements:\n",
      "[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 19, 20, 21, 26, 27, 30, 33, 37, 38, 39, 40, 41, 42, 43, 45, 54, 57, 60, 63, 64, 65, 66, 75, 77, 78, 83, 85, 91, 93, 94, 96, 97, 99, 102, 104, 110, 114, 117, 118, 119, 120, 122, 125, 128, 132, 133, 140, 141, 142, 143, 144, 146, 148, 155, 157, 158, 159, 160, 162, 163, 168, 172, 174, 175, 176, 179, 180, 183, 184, 185, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 219, 220, 221, 224, 226, 228, 229, 230, 231, 233, 234, 240, 242, 243, 252, 254, 255, 256, 258, 259, 260, 264, 265, 266, 268, 269, 270, 272, 289, 292, 293, 295, 298, 300, 301, 307, 308, 309, 311, 314, 320, 322, 331, 332, 340]\n",
      "The maximum number of elements:\n",
      "340\n",
      "833\n",
      "The maximum length of a sequence is that 2948\n",
      "[ =                    ] 8.52%(20298, 20, 341)\n",
      "done\n",
      "[Pickle]: save object into array_test.pickle\n",
      "4373\n",
      "Skip the file ADFA-LD/Validation_Data_Master/.DS_Store\n",
      "The total unique elements:\n",
      "[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 19, 20, 21, 22, 26, 27, 30, 33, 37, 38, 39, 40, 41, 42, 43, 45, 54, 57, 60, 61, 63, 64, 65, 66, 75, 77, 78, 79, 83, 85, 90, 91, 93, 94, 96, 97, 99, 102, 104, 110, 111, 114, 116, 117, 118, 119, 120, 122, 124, 125, 128, 132, 133, 136, 140, 141, 142, 143, 144, 146, 148, 150, 151, 154, 155, 156, 157, 158, 159, 160, 162, 163, 168, 172, 174, 175, 176, 177, 179, 180, 181, 183, 184, 185, 186, 187, 190, 191, 192, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 224, 226, 228, 229, 231, 234, 240, 243, 252, 254, 255, 256, 258, 259, 260, 264, 265, 266, 268, 269, 270, 272, 289, 292, 293, 295, 296, 298, 300, 301, 306, 307, 308, 309, 311, 314, 320, 324, 328, 331, 332, 340]\n",
      "The maximum number of elements:\n",
      "340\n",
      "4372\n",
      "The maximum length of a sequence is that 4494\n",
      "[                      ] 1.26%(21238, 20, 341)\n",
      "done\n",
      "[Pickle]: save object into array_val.pickle\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "#import io_helper\n",
    "\n",
    "def readfilesfromAdir(dataset):\n",
    "    #read a list of files\n",
    "    files = os.listdir(dataset)\n",
    "    files_absolute_paths = []\n",
    "    for i in files:\n",
    "        files_absolute_paths.append(dataset+str(i))\n",
    "    return files_absolute_paths\n",
    "\n",
    "\n",
    "file = \"ADFA-LD/Training_Data_Master/UTD-0001.txt\"\n",
    "#this is used to read a char sequence from\n",
    "def readCharsFromFile(file):\n",
    "    channel_values = open(file).read().split()\n",
    "    #print (len(channel_values))\n",
    "    #channel_values is a list\n",
    "    return channel_values\n",
    "    #print (channel_values[800:819])\n",
    "\n",
    "def get_attack_subdir(path):\n",
    "    subdirectories = os.listdir(path)\n",
    "    for i in range(0,len(subdirectories)):\n",
    "        subdirectories[i] = path + subdirectories[i]\n",
    "\n",
    "    print (subdirectories)\n",
    "    return (subdirectories)\n",
    "\n",
    "\n",
    "def get_all_call_sequences(dire):\n",
    "    files = readfilesfromAdir(dire)\n",
    "    allthelist = []\n",
    "    print (len(files))\n",
    "\n",
    "    for eachfile in files:\n",
    "        if not eachfile.endswith(\"DS_Store\"):\n",
    "            allthelist.append(readCharsFromFile(eachfile))\n",
    "        else:\n",
    "            print (\"Skip the file \"+ str(eachfile))\n",
    "\n",
    "    elements = []\n",
    "    for item in allthelist:\n",
    "        for key in item:\n",
    "            if key not in elements:\n",
    "                elements.append(key)\n",
    "\n",
    "    elements = map(int,elements)\n",
    "    elements = sorted(elements)\n",
    "\n",
    "    print (\"The total unique elements:\")\n",
    "    print (elements)\n",
    "\n",
    "    print (\"The maximum number of elements:\")\n",
    "    print (max(elements))\n",
    "\n",
    "    #print (\"The length elements:\")\n",
    "    #print (len(elements))\n",
    "    print (len(allthelist))\n",
    "\n",
    "    #clean the all list data set\n",
    "    _max = 0\n",
    "    for i in range(0,len(allthelist)):\n",
    "        _max = max(_max,len(allthelist[i]))\n",
    "        allthelist[i] = list(map(int,allthelist[i]))\n",
    "        #print(allthelist[i])\n",
    "\n",
    "\n",
    "    print (\"The maximum length of a sequence is that {}\".format(_max))\n",
    "\n",
    "    return (allthelist)\n",
    "\n",
    "## shift the data for analysis\n",
    "def shift(seq, n):\n",
    "    n = n % len(seq)\n",
    "    return seq[n:] + seq[:n]\n",
    "\n",
    "\n",
    "def convertToOneHot(vector, num_classes=None):\n",
    "    \"\"\"\n",
    "    Converts an input 1-D vector of integers into an output\n",
    "    2-D array of one-hot vectors, where an i'th input value\n",
    "    of j will set a '1' in the i'th row, j'th column of the\n",
    "    output array.\n",
    "\n",
    "    Example:\n",
    "        v = np.array((1, 0, 4))\n",
    "        one_hot_v = convertToOneHot(v)\n",
    "        print one_hot_v\n",
    "\n",
    "        [[0 1 0 0 0]\n",
    "         [1 0 0 0 0]\n",
    "         [0 0 0 0 1]]\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(vector, np.ndarray)\n",
    "    assert len(vector) > 0\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(vector)+1\n",
    "    else:\n",
    "        assert num_classes > 0\n",
    "        assert num_classes >= np.max(vector)\n",
    "\n",
    "    result = np.zeros(shape=(len(vector), num_classes))\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result.astype(int)\n",
    "\n",
    "\"\"\"\n",
    "The num_class here is set as 341\n",
    "\"\"\"\n",
    "\n",
    "#one function do one thing\n",
    "def sequence_n_gram_parsing(alist,n_gram=20,num_class=341):\n",
    "    if len(alist) <= n_gram:\n",
    "        return alist\n",
    "\n",
    "    ans = []\n",
    "    for i in range(0,len(alist)-n_gram+1,1):\n",
    "        tmp = alist[i:i+n_gram]\n",
    "        oneHot = convertToOneHot(np.asarray(tmp), num_class)\n",
    "        ans.append(oneHot)\n",
    "\n",
    "    #transform into nmup arrray\n",
    "    ans = np.array(ans)\n",
    "    return (ans)\n",
    "\n",
    "def lists_of_list_into_big_matrix(allthelist,n_gram=20):\n",
    "\n",
    "    array = sequence_n_gram_parsing(allthelist[0])\n",
    "\n",
    "    for i in range(1,len(allthelist),1):\n",
    "        tmp = sequence_n_gram_parsing(allthelist[i])\n",
    "\n",
    "       # print (\"tmp shape\")\n",
    "       # print (tmp.shape)\n",
    "\n",
    "        array = np.concatenate((array, tmp), axis=0)\n",
    "\n",
    "\n",
    "        percent = (i+0.0)/len(allthelist)\n",
    "        #io_helper.drawProgressBar(percent)\n",
    "        drawProgressBar(percent)\n",
    "\n",
    "        if (len(array)> 20000):\n",
    "            break\n",
    "        #print (\"array shape\")\n",
    "        #print (array.shape)\n",
    "\n",
    "\n",
    "    print (array.shape)\n",
    "    print (\"done\")\n",
    "    #io_helper.saveintopickle(array,\"array_test.pickle\")\n",
    "    saveintopickle(array,\"array_test.pickle\")\n",
    "\n",
    "\n",
    "def lists_of_list_into_big_matrix_val(allthelist,n_gram=20):\n",
    "\n",
    "    array = sequence_n_gram_parsing(allthelist[0])\n",
    "\n",
    "    for i in range(1,len(allthelist),1):\n",
    "        tmp = sequence_n_gram_parsing(allthelist[i])\n",
    "\n",
    "       # print (\"tmp shape\")\n",
    "       # print (tmp.shape)\n",
    "\n",
    "        array = np.concatenate((array, tmp), axis=0)\n",
    "\n",
    "\n",
    "        percent = (i+0.0)/len(allthelist)\n",
    "        #io_helper.drawProgressBar(percent)\n",
    "        drawProgressBar(percent)\n",
    "\n",
    "        if (len(array)> 20000):\n",
    "            break\n",
    "        #print (\"array shape\")\n",
    "        #print (array.shape)\n",
    "\n",
    "\n",
    "    print (array.shape)\n",
    "    print (\"done\")\n",
    "    #io_helper.saveintopickle(array,\"array_test.pickle\")\n",
    "    saveintopickle(array,\"array_val.pickle\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dirc = \"ADFA-LD/Training_Data_Master/\"\n",
    "    dirc_val = \"ADFA-LD/Validation_Data_Master/\"\n",
    "    dic_attack =\"ADFA-LD/Attack_Data_Master/\"\n",
    "    #train1 = get_all_call_sequences(dirc)\n",
    "\n",
    "    #test = [i for i in range(0,300)]\n",
    "    #array = sequence_n_gram_parsing(test)\n",
    "    #print (type(array))\n",
    "    #print (array.shape)\n",
    "\n",
    "    #get_attack_subdir(dic_attack)\n",
    "    #print (\"XxxxxxxXXXXXXXXXXX\")\n",
    "    #val1 = get_all_call_sequences(dirc_val)\n",
    "    att = get_all_call_sequences(dirc)\n",
    "    lists_of_list_into_big_matrix(att)\n",
    "    att_val = get_all_call_sequences(dirc_val)\n",
    "    lists_of_list_into_big_matrix_val(att_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "#import preprocess\n",
    "\n",
    "# Global hyper-parameters\n",
    "sequence_length = 19\n",
    "epochs = 1\n",
    "batch_size = 50\n",
    "feature_dimension = 341\n",
    "\n",
    "\n",
    "def save_model_weight_into_file(model, modelname=\"model.json\", weight=\"model.h5\"):\n",
    "    model_json = model.to_json()\n",
    "    with open(modelname, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(weight)\n",
    "    print(\"Saved model to disk in {} and {}\".format(modelname,weight))\n",
    "\n",
    "\n",
    "def load_model_and_wieght_from_file(modelname=\"model.json\", weight=\"model.h5\"):\n",
    "\n",
    "    json_file = open(modelname, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weight)\n",
    "    print(\"Loaded model from disk, you can do more analysis more\")\n",
    "\n",
    "    pass\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    layers = {'input': feature_dimension, 'hidden1': 64, 'hidden2': 256, 'hidden3': 100, 'output': feature_dimension}\n",
    "\n",
    "    model.add(LSTM(\n",
    "            input_length=sequence_length,\n",
    "            input_dim=layers['input'],\n",
    "            output_dim=layers['hidden1'],\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden2'],\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden3'],\n",
    "            return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "            output_dim=layers['output'],activation='softmax'))\n",
    "    #model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop',  metrics=['accuracy'])\n",
    "    #model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "\n",
    "    #print (\"Compilation Time : \"%(time.time() - start))\n",
    "    return model\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def run_network(model=None, data=None):\n",
    "\n",
    "    global_start_time = time.time()\n",
    "    \n",
    "    if data is None:\n",
    "        print ('Loading data... ')\n",
    "        # train on first 700 samples and test on next 300 samples (has anomaly)\n",
    "        X_train, y_train  = preprocess()\n",
    "    else:\n",
    "        X_train, y_train = data\n",
    "\n",
    "    print (\"X_train, y_train,shape\")\n",
    "    print (X_train.shape)\n",
    "    print (y_train.shape)\n",
    "    print ('\\nData Loaded. Compiling...\\n')\n",
    "\n",
    "    if model is None:\n",
    "        model = build_model()\n",
    "        print(\"Training...\")\n",
    "        model.fit(\n",
    "                X_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_split=0.05)\n",
    "        model.summary()\n",
    "        print(\"Done Training...\")\n",
    "\n",
    "    #predicted = model.predict(X_test)\n",
    "    #print(\"Reshaping predicted\")\n",
    "    #predicted = np.reshape(predicted, (predicted.size,))\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \"\"\"\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"prediction exception\")\n",
    "        print 'Training duration (s) : ', time.time() - global_start_time\n",
    "        return model, y_test, 0\n",
    "   \n",
    "    try:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(311)\n",
    "        plt.title(\"Actual Test Signal w/Anomalies\")\n",
    "        plt.plot(y_test[:len(y_test)], 'b')\n",
    "        plt.subplot(312)\n",
    "        plt.title(\"Predicted Signal\")\n",
    "        plt.plot(predicted[:len(y_test)], 'g')\n",
    "        plt.subplot(313)\n",
    "        plt.title(\"Squared Error\")\n",
    "        mse = ((y_test - predicted) ** 2)\n",
    "        plt.plot(mse, 'r')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"plotting exception\")\n",
    "        print (str(e))\n",
    "    print ('Training duration (s) : '% (time.time() - global_start_time))\n",
    "\n",
    "    return model, y_test, predicted\n",
    "   \"\"\"\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "# run_network()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "The train data size is that \n",
      "(20298, 19, 341)\n",
      "(20298, 341)\n",
      "X_train, y_train,shape\n",
      "(20298, 19, 341)\n",
      "(20298, 341)\n",
      "\n",
      "Data Loaded. Compiling...\n",
      "\n",
      "Training...\n",
      "Train on 19283 samples, validate on 1015 samples\n",
      "Epoch 1/1\n",
      "19283/19283 [==============================] - 31s 2ms/step - loss: 2.7311 - acc: 0.2456 - val_loss: 2.2571 - val_acc: 0.2808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 19, 64)            103936    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 19, 256)           328704    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 19, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 100)               142800    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 341)               34441     \n",
      "=================================================================\n",
      "Total params: 609,881\n",
      "Trainable params: 609,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done Training...\n"
     ]
    }
   ],
   "source": [
    "global_start_time = time.time()\n",
    "    \n",
    "model=None\n",
    "\n",
    "print ('Loading data... ')\n",
    "# train on first 700 samples and test on next 300 samples (has anomaly)\n",
    "X_train, y_train  = preprocess()\n",
    "\n",
    "print (\"X_train, y_train,shape\")\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print ('\\nData Loaded. Compiling...\\n')\n",
    "\n",
    "if model is None:\n",
    "    model = build_model()\n",
    "    print(\"Training...\")\n",
    "    history = model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.05,\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "    model.summary()\n",
    "    print(\"Done Training...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#def loadData(file): \n",
    "    # for reading also binary mode is important \n",
    "#    dbfile = open(file, 'rb')      \n",
    "#    db = pickle.load(dbfile) \n",
    "#    for keys in db: \n",
    "#        print(keys, '=>', db[keys]) \n",
    "#    dbfile.close() \n",
    "  \n",
    "#if __name__ == '__main__': \n",
    "#    loadData(\"./array_test.pickle\") \n",
    "#df_val = pd.read_pickle(\"./array_val.pickle\")\n",
    "#df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data size is that \n",
      "(21238, 19, 341)\n",
      "(21238, 341)\n",
      "X_test, y_test,shape\n",
      "(21238, 19, 341)\n",
      "(21238, 341)\n",
      "Validating...\n",
      "Done Validating...\n",
      "[[5.03549074e-07 5.11274324e-04 1.90999685e-06 ... 6.67329573e-07\n",
      "  7.41592942e-07 6.66175220e-06]\n",
      " [8.51366792e-07 5.51261590e-04 3.50256823e-06 ... 1.30128683e-06\n",
      "  1.29121929e-06 1.07382693e-05]\n",
      " [4.46622835e-07 5.26654825e-04 1.81123414e-06 ... 6.48105015e-07\n",
      "  7.11315522e-07 6.07781658e-06]\n",
      " ...\n",
      " [2.37265867e-05 2.50867661e-03 2.65557974e-05 ... 2.01402763e-05\n",
      "  1.91918843e-05 1.12194786e-04]\n",
      " [2.39555939e-05 2.51514651e-03 2.68349286e-05 ... 2.03429117e-05\n",
      "  1.94765016e-05 1.12630878e-04]\n",
      " [2.04245025e-05 2.35214341e-03 2.36305568e-05 ... 1.74006982e-05\n",
      "  1.64858102e-05 9.88534739e-05]]\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17\n",
    "\n",
    "X_test, y_test = preprocess_val()\n",
    "\n",
    "print (\"X_test, y_test,shape\")\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)\n",
    "\n",
    "print(\"Validating...\")\n",
    "predicted = model.predict(X_test)\n",
    "print(\"Done Validating...\")\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did our model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 2.64\n",
      "Validation Accuracy : 0.37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score, accuracy = model.evaluate(X_test, y_test, verbose=2, batch_size=batch_size)\n",
    "print('Score : %.2f'%(score))\n",
    "print('Validation Accuracy : %.2f'%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [2.2570636331154206],\n",
       " 'val_acc': [0.28078817759681807],\n",
       " 'loss': [2.7311162518705685],\n",
       " 'acc': [0.2456049372040279]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Test with new systemcall  sequence ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
